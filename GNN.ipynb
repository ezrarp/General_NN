{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colledge admissions algorithm\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuralstructure:\n",
    "    \"\"\"\n",
    "    input_size: number of input nodes\n",
    "    layers: number of hidden layers\n",
    "    nodes_per_layer: number of nodes per hidden layer\n",
    "    output_size: number of output nodes\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int , layers: int, nodes_per_layer: list, output_size: int):\n",
    "        self.input_size = input_size\n",
    "        self.layers = layers\n",
    "        self.nodes_per_layer = nodes_per_layer\n",
    "        self.output_size = output_size\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.init_weights()\n",
    "        self.init_bias()\n",
    "        if len(nodes_per_layer) != layers:\n",
    "            raise Exception(\"Number of layers and number of nodes per layer must be equal\")\n",
    "        if layers < 1:\n",
    "            raise Exception(\"Number of layers must be greater than 0\")\n",
    "        if input_size < 1:\n",
    "            raise Exception(\"Input size must be greater than 0\")\n",
    "        if output_size < 1:\n",
    "            raise Exception(\"Output size must be greater than 0\")\n",
    "        for i in range(layers):\n",
    "            if nodes_per_layer[i] < 1:\n",
    "                raise Exception(\"Number of nodes per layer must be greater than 0\")\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for i in range(self.layers):\n",
    "            if i == 0:\n",
    "                self.weights.append(np.random.rand(self.input_size, self.nodes_per_layer[i]))\n",
    "            else:\n",
    "                self.weights.append(np.random.rand(self.nodes_per_layer[i-1], self.nodes_per_layer[i]))\n",
    "        self.weights.append(np.random.rand(self.nodes_per_layer[self.layers-1], self.output_size))\n",
    "    \n",
    "    def init_bias(self):\n",
    "        for i in range(self.layers):\n",
    "            self.bias.append(np.random.rand(self.nodes_per_layer[i]))\n",
    "        self.bias.append(np.random.rand(self.output_size))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, structure: Neuralstructure , learning_rate: float):\n",
    "        self.structure = structure\n",
    "        self.weights = structure.weights\n",
    "        self.bias = structure.bias\n",
    "        self.layers = structure.layers\n",
    "        self.nodes_per_layer = structure.nodes_per_layer\n",
    "        self.input_size = structure.input_size\n",
    "        self.output_size = structure.output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.outputs = []\n",
    "        self.mean = 0\n",
    "        self.std = 0\n",
    "        self.normalized = False\n",
    "\n",
    "    def normalize(self, inputs: np.array):\n",
    "        if not self.normalized:\n",
    "            self.mean = np.mean(inputs, axis=0)\n",
    "            self.std = np.std(inputs, axis=0)\n",
    "            self.normalized = True\n",
    "            return (inputs - self.mean) / self.std\n",
    "        else:\n",
    "            return (inputs - self.mean) / self.std\n",
    "\n",
    "    def feed_forward(self, inputs: np.array):\n",
    "        self.outputs = []\n",
    "        for i in range(len(inputs)):\n",
    "            if len(inputs[i]) != self.input_size:\n",
    "                raise Exception(\"Input size does not match input layer size\")\n",
    "            self.output = []\n",
    "            self.output.append(inputs[i])\n",
    "            for j in range(self.layers):\n",
    "                self.output.append(sigmoid(np.dot(self.output[j], self.weights[j]) + self.bias[j]))  \n",
    "            self.output.append(sigmoid(np.dot(self.output[self.layers], self.weights[self.layers]) + self.bias[self.layers]))\n",
    "            if self.output[-1] > 0.5:\n",
    "                self.output[-1] = 1\n",
    "            else:\n",
    "                self.output[-1] = 0\n",
    "            self.outputs.append(self.output)\n",
    "        return self.outputs\n",
    "\n",
    "    \n",
    "    def backwards(self, inputs: np.array, targets: np.array):\n",
    "        self.feed_forward(inputs)\n",
    "        activations = self.outputs\n",
    "\n",
    "        r = np.array([sub_list[-1] for sub_list in activations])\n",
    "        mse = np.mean(np.square(targets - r))\n",
    "\n",
    "        for i in range(len(activations)):\n",
    "            \n",
    "            a = activations[i]\n",
    "            output_error = targets[i] - a[-1]\n",
    "\n",
    "            for j in range(self.layers, 0, -1):\n",
    "                error = output_error * sigmoid_prime(a[j])\n",
    "                output_error = error.dot(self.weights[j].T[0])\n",
    "\n",
    "                self.weights[j] += self.learning_rate * a[j].T.dot(error)\n",
    "                self.bias[j] += self.learning_rate * np.sum(error, axis=0, keepdims=True)\n",
    "\n",
    "            error = output_error * sigmoid_prime(a[0])\n",
    "\n",
    "            \n",
    "            self.weights[0] += self.learning_rate * inputs[i].T.dot(error)\n",
    "            self.bias[0] += self.learning_rate * np.sum(error, axis=0, keepdims=True)\n",
    "        return mse \n",
    "\n",
    "\n",
    "    \n",
    "    def train(self, inputs: np.array, targets: np.array, epochs: int):\n",
    "        \"\"\"\n",
    "        inputs: array of inputs\n",
    "        targets: array of targets\n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            mse = self.backwards(inputs, targets)\n",
    "        if epochs % 100 == 0:\n",
    "            print(mse)\n",
    "\n",
    "\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_structure(input_size: int, layers:int):\n",
    "    nodes_per_layer = []\n",
    "    average = input_size / layers\n",
    "\n",
    "    for i in range(layers):\n",
    "        n = int(round(input_size - (average * i))) + 1\n",
    "        if n < 1:\n",
    "            nodes_per_layer.append(1)\n",
    "        else:\n",
    "            nodes_per_layer.append(n)\n",
    "    return nodes_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(layers, output_size):\n",
    "    \"\"\" \n",
    "    setup the neural network\n",
    "    layers: number of hidden layers\n",
    "    output_size: number of output nodes\n",
    "    filename:'input.csv'\n",
    "    \"\"\"\n",
    "    data = pd.read_csv('input.csv')\n",
    "    header = data.columns.to_list()\n",
    "    result = header[-1]\n",
    "    y_train = data[result]\n",
    "    x_train = data.drop(result, axis=1)\n",
    "    x_train = x_train.fillna(0)\n",
    "    y_train = y_train.values\n",
    "    x_train = x_train.values\n",
    "    input_size = len(header) - 1\n",
    "    nodes = node_structure(input_size, layers)\n",
    "\n",
    "    ns = Neuralstructure(input_size, layers, nodes, output_size)\n",
    "    nn = NeuralNetwork(ns, 0.1)\n",
    "    x_train = nn.normalize(x_train)\n",
    "    nn.train(x_train, y_train, 1500)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "network = setup(3, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.nodes_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, inputs):\n",
    "    network.normalize(inputs)\n",
    "    preditions = network.feed_forward(inputs)\n",
    "    predictions = [sub_list[-1] for sub_list in preditions]\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "input = np.array([[1,1], [1,0], [0,1], [0,0]])\n",
    "print(predict(network, input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
